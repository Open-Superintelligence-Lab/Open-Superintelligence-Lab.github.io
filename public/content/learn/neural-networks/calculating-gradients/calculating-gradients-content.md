---
hero:
  title: "Calculating Gradients"
  subtitle: "Understanding Gradient Computation"
  tags:
    - "üß† Neural Networks"
    - "‚è±Ô∏è 8 min read"
---

Gradients tell us **which direction** to adjust weights to reduce loss!

## The Mathematical Essence

Gradients are the foundation of how neural networks learn. Without understanding gradients, deep learning remains a black box. Let's demystify them!

### What is a Gradient?

**Gradient = Rate of change of loss with respect to a parameter**

Mathematically:
```
‚àÇL/‚àÇw = lim[h‚Üí0] (L(w+h) - L(w))/h

This tells us: "If I change w by a tiny amount, how does L change?"
```

**In practical terms:**
- Positive gradient: Increasing weight increases loss ‚Üí decrease weight
- Negative gradient: Increasing weight decreases loss ‚Üí increase weight
- Large |gradient|: Loss is very sensitive to this weight
- Small |gradient|: Loss barely affected by this weight

### A Simple Example

Let's compute a gradient manually, then verify with PyTorch:

**Function:** loss = w¬≤

**Manual derivative:**
```
d/dw (w¬≤) = 2w
```

If w = 3, then gradient = 2(3) = 6

**In code:**

```python
import torch

# Simple function: loss = w¬≤
w = torch.tensor([3.0], requires_grad=True)
loss = w ** 2

# Calculate gradient
loss.backward()

print(f"Weight: {w.item()}")        # 3.0
print(f"Loss: {loss.item()}")       # 9.0
print(f"Gradient: {w.grad.item()}")  # 6.0
```

**Interpretation:**
```
Gradient = 6.0 (positive)
‚Üí If we increase w, loss increases
‚Üí If we decrease w, loss decreases
‚Üí So we should decrease w to minimize loss!
```

Let's verify:
```
Current: w=3, loss=9
If w=2.9: loss=8.41 (decreased!) ‚úì
If w=3.1: loss=9.61 (increased!) ‚úì
```

## Computing Gradients in Neural Networks

Now let's see gradients in a real network with multiple parameters:

### Step 1: Create a Simple Network

```python
import torch
import torch.nn as nn

# Single neuron: 3 inputs ‚Üí 1 output
model = nn.Linear(3, 1)

# Check initial parameters
print(f"Weights shape: {model.weight.shape}")  # torch.Size([1, 3])
print(f"Bias shape: {model.bias.shape}")        # torch.Size([1])
```

**Parameters:** 3 weights + 1 bias = 4 learnable parameters

### Step 2: Prepare Data

```python
x = torch.tensor([[1.0, 2.0, 3.0]])  # Input
y_true = torch.tensor([[5.0]])        # Target
```

### Step 3: Forward Pass

```python
y_pred = model(x)  # Make prediction
print(f"Prediction: {y_pred.item():.3f}")

loss = (y_pred - y_true) ** 2  # Calculate loss
print(f"Loss: {loss.item():.3f}")
```

Let's say the prediction is 2.5. Then:
```
Loss = (2.5 - 5.0)¬≤ = (-2.5)¬≤ = 6.25
```

Our prediction is way off!

### Step 4: Compute Gradients

This is where the magic happens:

```python
loss.backward()  # Compute gradients for ALL parameters

# Check gradients for each parameter
print("Weight gradients:", model.weight.grad)
# tensor([[-5.0000, -10.0000, -15.0000]])

print("Bias gradient:", model.bias.grad)
# tensor([-5.0000])
```

**What these gradients mean:**
```
‚àÇL/‚àÇw‚ÇÅ = -5.0  ‚Üí Increasing w‚ÇÅ decreases loss (negative gradient)
‚àÇL/‚àÇw‚ÇÇ = -10.0 ‚Üí Increasing w‚ÇÇ decreases loss even more!
‚àÇL/‚àÇw‚ÇÉ = -15.0 ‚Üí Increasing w‚ÇÉ has the strongest effect
‚àÇL/‚àÇb = -5.0   ‚Üí Increasing bias decreases loss
```

All gradients are negative, telling us to **increase all parameters** to reduce loss.

### Why Different Gradient Magnitudes?

Notice w‚ÇÉ has the largest gradient (-15). Why?

```
‚àÇL/‚àÇw·µ¢ depends on the input x·µ¢!

Input was [1.0, 2.0, 3.0]
  x‚ÇÉ = 3.0 is largest
  ‚Üí w‚ÇÉ has largest impact on output
  ‚Üí w‚ÇÉ has largest gradient

This is the chain rule at work!
```

## Using Gradients to Update Weights

Now that we have gradients, let's use them to improve our model:

### The Update Rule

Gradient descent update: **new_param = old_param - learning_rate √ó gradient**

```python
learning_rate = 0.01

# Manual update (PyTorch normally does this for you)
with torch.no_grad():  # Don't track these operations
    for param in model.parameters():
        # The update step
        param -= learning_rate * param.grad
        
        # Reset gradient for next iteration
        param.grad.zero_()
```

### Understanding the Update

Let's trace what happens to one weight:

```
Before:
  w‚ÇÅ = 0.5
  gradient = -5.0
  learning_rate = 0.01

Update:
  w‚ÇÅ_new = w‚ÇÅ - (learning_rate √ó gradient)
        = 0.5 - (0.01 √ó -5.0)
        = 0.5 - (-0.05)
        = 0.5 + 0.05
        = 0.55

After: w‚ÇÅ = 0.55 (increased!)
```

**Why did it increase?** Negative gradient means "go up" to reduce loss!

### The Complete Training Cycle

```python
# Full cycle with visualization
print("Before training:")
print(f"  Prediction: {model(x).item():.3f}")
print(f"  Loss: {loss.item():.3f}")

# One update step
optimizer.zero_grad()
loss.backward()
optimizer.step()

# Check improvement
new_pred = model(x)
new_loss = (new_pred - y_true) ** 2

print("\\nAfter one update:")
print(f"  Prediction: {new_pred.item():.3f}")
print(f"  Loss: {new_loss.item():.3f}")
print(f"  Improvement: {(loss.item() - new_loss.item()):.3f}")
```

**Expected output:**
```
Before training:
  Prediction: 2.500
  Loss: 6.250

After one update:
  Prediction: 2.650
  Loss: 5.523
  Improvement: 0.727
```

One step closer to the target!

## Key Takeaways

‚úì **Gradient:** Direction and magnitude of change

‚úì **`.backward()`:** Computes all gradients

‚úì **Automatic:** PyTorch calculates for you

‚úì **Update rule:** param -= lr * gradient

**Quick Reference:**

```python
# Compute gradients
loss.backward()

# Access gradients
param.grad

# Zero gradients
optimizer.zero_grad()
# or
param.grad.zero_()
```

**Remember:** Gradients point the way to better weights! üéâ
