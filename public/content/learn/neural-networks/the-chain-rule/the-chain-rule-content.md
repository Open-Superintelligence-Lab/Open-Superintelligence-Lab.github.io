---
hero:
  title: "The Chain Rule"
  subtitle: "The Math Behind Backpropagation"
  tags:
    - "üß† Neural Networks"
    - "‚è±Ô∏è 8 min read"
---

The chain rule is how we calculate gradients through multiple layers. It's the secret sauce of backpropagation!

## Why the Chain Rule Matters

Without the chain rule, we couldn't train deep neural networks. It's the mathematical tool that lets us figure out how to adjust weights in layer 1 based on errors in layer 10!

Think of it like this: If you burn a cake, you need to figure out which step in the recipe went wrong. Was it the oven temperature? The mixing time? The ingredient proportions? The chain rule helps us trace back through all the steps.

### The Mathematical Foundation

**Chain rule from calculus:**

If you have a composition of functions:
```
y = f(g(h(x)))

Then the derivative is:
dy/dx = (df/dg) √ó (dg/dh) √ó (dh/dx)
```

**In words:** To find how x affects y, multiply all the intermediate derivatives!

### A Visual Understanding

```
x ‚Üí [h] ‚Üí h(x) ‚Üí [g] ‚Üí g(h(x)) ‚Üí [f] ‚Üí y=f(g(h(x)))

Backward (chain rule):
dy/dx ‚Üê dy/df √ó df/dg ‚Üê dy/dg √ó dg/dh ‚Üê dy/dh √ó dh/dx
```

Each arrow represents one multiplication in the chain!

## The Basic Idea

**Chain rule: Multiply gradients as you go backwards through layers**

```yaml
If y = f(g(x)), then:
dy/dx = (dy/dg) √ó (dg/dx)

In words: Multiply the gradients of each function
```

This extends to any number of nested functions!

## Simple Example from First Principles

Let's manually derive a gradient using the chain rule, then verify with PyTorch:

### The Problem

Compute the gradient of y = (x + 2)¬≤ with respect to x.

### Manual Solution (Chain Rule)

**Step 1: Break into components**
```
Let g = x + 2
Then y = g¬≤
```

**Step 2: Find individual derivatives**
```
dg/dx = d/dx(x + 2) = 1
dy/dg = d/dg(g¬≤) = 2g
```

**Step 3: Apply chain rule**
```
dy/dx = (dy/dg) √ó (dg/dx)
      = 2g √ó 1
      = 2(x + 2)
```

**Step 4: Evaluate at x = 3**
```
dy/dx = 2(3 + 2) = 2(5) = 10
```

### Verification with PyTorch

```python
import torch

x = torch.tensor([3.0], requires_grad=True)

# Build the computation graph
g = x + 2    # Intermediate value
y = g ** 2   # Final output

# One line computes the gradient!
y.backward()

print(f"x = {x.item()}")              # 3.0
print(f"g = {g.item()}")              # 5.0
print(f"y = {y.item()}")              # 25.0
print(f"dy/dx = {x.grad.item()}")    # 10.0
```

**Manual verification:**
```
dy/dg = 2g = 2(5) = 10
dg/dx = 1
dy/dx = 10 √ó 1 = 10 ‚úì

PyTorch got it right!
```

### Visualizing the Gradient Flow

```
Forward:
x=3 ‚Üí [+2] ‚Üí g=5 ‚Üí [¬≤] ‚Üí y=25

Backward (chain rule):
dy/dx=10 ‚Üê [√ó1] ‚Üê dy/dg=10 ‚Üê [√ó2g] ‚Üê dy/dy=1
```

Each backward step multiplies the gradient!

## Chain Rule in Neural Networks

Let's see how this applies to actual neural network training:

### The Network Structure

```python
import torch
import torch.nn as nn

# Two-layer network
model = nn.Sequential(
    nn.Linear(1, 1),  # Layer 1: y‚ÇÅ = w‚ÇÅx + b‚ÇÅ
    nn.ReLU(),         # Activation: a‚ÇÅ = max(0, y‚ÇÅ)
    nn.Linear(1, 1)    # Layer 2: y‚ÇÇ = w‚ÇÇa‚ÇÅ + b‚ÇÇ
)
```

**Mathematical representation:**
```
x ‚Üí Linear(w‚ÇÅ,b‚ÇÅ) ‚Üí y‚ÇÅ ‚Üí ReLU ‚Üí a‚ÇÅ ‚Üí Linear(w‚ÇÇ,b‚ÇÇ) ‚Üí y‚ÇÇ ‚Üí Loss
```

### Forward Pass

```python
x = torch.tensor([[2.0]])
y_true = torch.tensor([[10.0]])

# Forward computation
y_pred = model(x)
loss = (y_pred - y_true) ** 2

print(f"Prediction: {y_pred.item():.3f}")
print(f"Loss: {loss.item():.3f}")
```

**What happened:**
```
x=2.0 ‚Üí w‚ÇÅ(2.0)+b‚ÇÅ ‚Üí ReLU ‚Üí w‚ÇÇ(ReLU)+b‚ÇÇ ‚Üí prediction
```

### Backward Pass (Chain Rule in Action!)

```python
# This one line applies chain rule through ALL layers!
loss.backward()

# Check gradients for each parameter
for name, param in model.named_parameters():
    print(f"{name}: gradient = {param.grad}")
```

**Output:**
```
0.weight: gradient = tensor([[...]])
0.bias: gradient = tensor([...])
2.weight: gradient = tensor([[...]])
2.bias: gradient = tensor([...])
```

### The Chain Rule Path

Let's trace the gradient flow mathematically:

**Backward through the network:**
```
‚àÇL/‚àÇL = 1 (start here)
  ‚Üì
‚àÇL/‚àÇy‚ÇÇ = 2(y‚ÇÇ - y_true)
  ‚Üì
‚àÇL/‚àÇw‚ÇÇ = (‚àÇL/‚àÇy‚ÇÇ) √ó (‚àÇy‚ÇÇ/‚àÇw‚ÇÇ) = (‚àÇL/‚àÇy‚ÇÇ) √ó a‚ÇÅ  (chain rule!)
  ‚Üì
‚àÇL/‚àÇa‚ÇÅ = (‚àÇL/‚àÇy‚ÇÇ) √ó (‚àÇy‚ÇÇ/‚àÇa‚ÇÅ) = (‚àÇL/‚àÇy‚ÇÇ) √ó w‚ÇÇ
  ‚Üì
‚àÇL/‚àÇy‚ÇÅ = (‚àÇL/‚àÇa‚ÇÅ) √ó (‚àÇa‚ÇÅ/‚àÇy‚ÇÅ) = (‚àÇL/‚àÇa‚ÇÅ) √ó ReLU'(y‚ÇÅ)
  ‚Üì
‚àÇL/‚àÇw‚ÇÅ = (‚àÇL/‚àÇy‚ÇÅ) √ó (‚àÇy‚ÇÅ/‚àÇw‚ÇÅ) = (‚àÇL/‚àÇy‚ÇÅ) √ó x  (chain rule!)
```

See how each gradient depends on the previous one? That's the chain!

### What Happens in Code

```yaml
Forward pass (PyTorch builds a graph):
  x ‚Üí Layer1 ‚Üí ReLU ‚Üí Layer2 ‚Üí prediction ‚Üí loss
  
Backward pass (PyTorch traverses graph backwards):
  ‚àÇL/‚àÇloss=1 ‚Üí ‚àÇL/‚àÇpred ‚Üí ‚àÇL/‚àÇLayer2 ‚Üí ‚àÇL/‚àÇReLU ‚Üí ‚àÇL/‚àÇLayer1 ‚Üí ‚àÇL/‚àÇx
  
Each step multiplies by local derivative (chain rule!)
```

## Why the Chain Rule Works

### The Dependency Chain

Everything is connected! Let's trace the dependencies:

```yaml
Loss depends on ‚Üí prediction (y‚ÇÇ)
Prediction depends on ‚Üí Layer 2 weights (w‚ÇÇ) and activated hidden (a‚ÇÅ)
Activated hidden depends on ‚Üí ReLU and Layer 1 output (y‚ÇÅ)
Layer 1 output depends on ‚Üí Layer 1 weights (w‚ÇÅ) and input (x)

Therefore: Loss depends on w‚ÇÅ (through the entire chain!)
```

**Mathematically:**
```
L = L(y‚ÇÇ(a‚ÇÅ(y‚ÇÅ(w‚ÇÅ, x))))

To find ‚àÇL/‚àÇw‚ÇÅ, we need to traverse the chain:
‚àÇL/‚àÇw‚ÇÅ = (‚àÇL/‚àÇy‚ÇÇ) √ó (‚àÇy‚ÇÇ/‚àÇa‚ÇÅ) √ó (‚àÇa‚ÇÅ/‚àÇy‚ÇÅ) √ó (‚àÇy‚ÇÅ/‚àÇw‚ÇÅ)
```

Each multiplication is one link in the chain!

### A Concrete Example

Let's compute actual numbers:

```
Suppose:
  ‚àÇL/‚àÇy‚ÇÇ = 2.0    (loss gradient)
  ‚àÇy‚ÇÇ/‚àÇa‚ÇÅ = 1.5   (w‚ÇÇ value)
  ‚àÇa‚ÇÅ/‚àÇy‚ÇÅ = 1.0   (ReLU derivative, assuming y‚ÇÅ>0)
  ‚àÇy‚ÇÅ/‚àÇw‚ÇÅ = 2.0   (x value)

Chain rule:
  ‚àÇL/‚àÇw‚ÇÅ = 2.0 √ó 1.5 √ó 1.0 √ó 2.0 = 6.0
```

This single number (6.0) tells us exactly how to adjust w‚ÇÅ!

## PyTorch Automates the Chain Rule

The beautiful thing? You never have to do this manually! PyTorch handles all the calculus:

### An Extremely Complex Function

Let's test PyTorch with a crazy composition of functions:

```python
import torch

x = torch.tensor([2.0], requires_grad=True)

# Insanely nested function!
y = ((x ** 2 + 3) * torch.sin(x)) ** 3
```

**Breakdown:**
```
Step 1: a = x¬≤
Step 2: b = a + 3
Step 3: c = sin(x)
Step 4: d = b √ó c
Step 5: y = d¬≥
```

That's a composition of 5+ functions! Computing dy/dx requires:
```
dy/dx = (dy/dd) √ó (dd/db) √ó (db/da) √ó (da/dx) √ó ...
        + (dy/dd) √ó (dd/dc) √ó (dc/dx)
```

Multiple paths through the computation graph!

### PyTorch Handles Everything

```python
# One line computes everything!
y.backward()

print(f"x = {x.item()}")
print(f"y = {y.item():.3f}")
print(f"Gradient: {x.grad.item():.3f}")
```

**What PyTorch did:**
1. Built computation graph during forward pass
2. Applied chain rule backwards through all operations
3. Accumulated gradients from multiple paths
4. Returned the final gradient

All the calculus done automatically!

## Key Takeaways

‚úì **Chain rule:** Multiply gradients backwards

‚úì **Backpropagation:** Applies chain rule through network

‚úì **Automatic:** PyTorch does it for you

‚úì **Essential:** Makes training deep networks possible

**Remember:** Chain rule lets us train deep networks by connecting all the gradients! üéâ
