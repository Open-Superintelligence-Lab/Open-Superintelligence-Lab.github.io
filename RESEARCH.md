### Open Tasks

[Does RoPE mess with semantics of the vectors, what would you do differently? ‚ûù](/blog/rope-semantics)

Setup research environment for [Back to Basics: Let Denoising Generative Models Denoise](https://arxiv.org/pdf/2511.13720). Add research questions, ideas, topics, etc.


---

### Arctices

### [DeepSeek Sparse Attention](/blog/deepseek-sparse-attention)
Advanced research on DeepSeek's innovative sparse attention mechanisms for efficient long-context processing.

### [Tiny Recursive Model](/blog/tiny-recursive-model)
How a 7M parameter model beats 100x bigger models at Sudoku, Mazes, and ARC-AGI using recursive reasoning.

### [Pretrain LLM with NVFP4](/blog/pretrain-llm-with-nvfp4)
NVIDIA's breakthrough 4-bit training methodology achieving 2-3x speedup and 50% memory reduction.

### [47x Faster Image Generation](/blog/diffusion-transformer-representation-autoencoder)
Diffusion Transformers with Representation Autoencoders achieve state-of-the-art FID 1.13 on ImageNet.

### [QeRL: Beyond Efficiency](/blog/qerl-quantization-reinforcement-learning)
Quantization-enhanced Reinforcement Learning for LLMs enables RL training of 32B models on a single GPU.