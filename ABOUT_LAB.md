**Open Superintelligence Lab** is a globally distributed and open AI research lab that aims to accelerate AI research 2x to 5x.

Currently the progress is happening in top tier universities and companies, however, there is a massive amount of people all over the world who just need a structured environment to start contributing to AI research, which will in turn accelerate technology and improve living standards for everyone.

We will allow **absolute research freedom**. You may get inspired by our suggestions, projects, tasks, ideas, or bring your own ideas to the table.

---

## Articles

### [Path To Open Superintelligence](/blog/path-to-open-superintelligence)
A strategic roadmap for building AGI through open collaboration, addressing key challenges and defining our path forward to create transformative AI systems.

### [DeepSeek Sparse Attention](/blog/deepseek-sparse-attention)
Advanced research on DeepSeek's innovative sparse attention mechanisms for efficient long-context processing.

### [Tiny Recursive Model](/blog/tiny-recursive-model)
How a 7M parameter model beats 100x bigger models at Sudoku, Mazes, and ARC-AGI using recursive reasoning.

### [Pretrain LLM with NVFP4](/blog/pretrain-llm-with-nvfp4)
NVIDIA's breakthrough 4-bit training methodology achieving 2-3x speedup and 50% memory reduction.

### [47x Faster Image Generation](/blog/diffusion-transformer-representation-autoencoder)
Diffusion Transformers with Representation Autoencoders achieve state-of-the-art FID 1.13 on ImageNet.

### [QeRL: Beyond Efficiency](/blog/qerl-quantization-reinforcement-learning)
Quantization-enhanced Reinforcement Learning for LLMs enables RL training of 32B models on a single GPU.

---

### External References & Inspirations
- [Back to Basics: Let Denoising Generative Models Denoise](https://arxiv.org/pdf/2511.13720)
- New sparsity factor for LLMs - making AI research even more accessible.